<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Wenzheng Zeng</title>

    <meta name="author" content="Wenzheng Zeng">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" type="image/png" href="/images/logo/18.png">


  </head>

  <body>
    <!-- <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> -->
    <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:0.5%;width:72%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  <!-- <span style="font-family: 'Times New Roman', Times, serif;">Wenzheng Zeng</span>  -->
                  Wenzheng Zeng   「曾文正」
                  <!-- <span style="font-family: 'SimSun', '宋体', serif;">曾文正</span> -->
                </p>
              </td>
              <!-- <td style="padding:0.5%;width:30%;vertical-align:middle">
              </td> -->
            </tr>
            <tr style="padding:0px">
              <td style="padding:0.5%;width:72%;vertical-align:middle">   
                <p>I am a first year PhD candidate at the National University of Singapore (NUS), 
                  affiliated with the <a href="https://www.comp.nus.edu.sg/">Department of Computer Science</a> 
                  and <a href="https://sites.google.com/view/showlab/home">Show Lab</a>, 
                  closely co-supervised by
                  <a href="https://scholar.google.com/citations?user=FABZCeAAAAAJ&hl">Prof. Hwee Tou Ng</a>
                  and
                  <a href="https://scholar.google.com/citations?user=h1-3lSoAAAAJ&hl">Prof. Mike Zheng Shou</a>.
                  I received my B.Eng and M.Phil degree from
                  <a href="https://aia.hust.edu.cn">School of Artificial Intelligence and Automation</a>,
                  <a href="https://english.hust.edu.cn">Huazhong University of Science and Technology (HUST)</a>, working with 
                  <a href="https://scholar.google.com/citations?user=NeKBuXEAAAAJ&hl">Prof. Yang Xiao</a>
                  and
                  <a href="https://scholar.google.com/citations?user=396o2BAAAAAJ&hl">Prof. Zhiguo Cao</a>, and also collaborating with
                  <a href="https://scholar.google.com/citations?user=cYNqDokAAAAJ&hl">Dr. Joey Tianyi Zhou</a>
                  and
                  <a href="https://scholar.google.com/citations?hl=en&user=fJ7seq0AAAAJ">Prof. Junsong Yuan</a>.

                </p>
                <p>
                  I work on computer vision research, with a primary focus on multimodal and spatiotemporal intelligence.
                </p>
                <!-- <p>
                  My hust.edu.cn email has expired since 2024.9. Feel free to contact me via [wenzhengzeng@u.nus.edu] or [zengwenzheng126@126.com].
                </p> -->
                <div class="social-links">
                  <a href="mailto:wenzhengzeng@u.nus.edu">Email</a>
                  <span class="sep">|</span>
                  <a href="https://scholar.google.com.sg/citations?hl=en&user=RDTJO-4AAAAJ">Google Scholar</a>
                  <span class="sep">|</span>
                  <a href="https://x.com/alexzeng1206" target="_blank" rel="noopener">X (Twitter)</a>
                  <span class="sep">|</span>
                  <a href="https://github.com/wenzhengzeng">Github</a>
                  <span class="sep">|</span>
                  <a href="https://www.zhihu.com/people/alex-31-36-62">知乎</a>
                </div>
                <!-- <p style="text-align:center">
                  <a href="https://twitter.com/alexzeng1206?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @alexzeng1206</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>  
                </p> -->



                
              </td>
              <td style="padding:0.5%;width:28%;vertical-align:top">
                <a href="images/zwz3.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/zwz3.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:10px;width:100%;vertical-align:middle">
                <h2>Selected Publications</h2>
                <p class="pub-legend">(*: equal contribution, &dagger;: project lead, &Dagger;: corresponding author)</p>

                
              </td>
            </tr>
          </tbody></table>

          <ul class="pub-list">
            <li class="publication-entry" onmouseout="slidetailor_stop()" onmouseover="slidetailor_start()">
              <img class="pub-thumb" src="images/slidetailor.png" alt="SlideTailor" />
              <div class="pub-body">
                <div class="pub-title">SlideTailor: Personalized Presentation Slide Generation for Scientific Papers</div>
                <div class="pub-meta">
                  <u><b>Wenzheng Zeng*</b></u>, Mingyu Ouyang*, Langyuan Cui*, Hwee Tou Ng<span class="supmark_1">&Dagger;</span>
                  <br />
                  <em>AAAI 2026</em>
                </div>
                <div class="pub-links">
                  <a href="https://arxiv.org/abs/2512.20292">[Paper]</a>
                  <a href="https://github.com/nusnlp/SlideTailor">[Code]</a>
                  <a href="https://drive.google.com/drive/folders/1N8p1A4eW8Nrrc2fN5NnIutG0og9u_GIy">[Poster]</a>
                  <a href="https://www.youtube.com/watch?v=NT5kWE6j_Vw">[Video]</a>
                  <a href="https://drive.google.com/drive/folders/1N8p1A4eW8Nrrc2fN5NnIutG0og9u_GIy">[Slides]</a>
                </div>
              </div>
            </li>

            <li class="publication-entry" onmouseout="d2vlm_stop()" onmouseover="d2vlm_start()">
              <img class="pub-thumb" src="images/d2vlm/1.png" alt="D2VLM" />
              <div class="pub-body">
                <div class="pub-title">Factorized Learning for Temporally Grounded Video-Language Models</div>
                <div class="pub-meta">
                  <u><b>Wenzheng Zeng</b></u>, Difei Gao, Mike Zheng Shou<span class="supmark_1">&Dagger;</span>, Hwee Tou Ng<span class="supmark_1">&Dagger;</span>
                  <br />
                  <em>ICCV 2025</em>
                </div>
                <div class="pub-links">
                  <a href="https://www.arxiv.org/pdf/2512.24097">[Paper]</a>
                  <a href="https://github.com/nusnlp/d2vlm">[Code]</a>
                  <a href="https://iccv.thecvf.com/media/PosterPDFs/ICCV%202025/1301.png?t=1759990615.5445755">[Poster]</a>
                  <a href="https://www.youtube.com/watch?v=DylkFjyTITs&t=2s">[Video]</a>
                </div>
              </div>
            </li>

            <li class="publication-entry" onmouseout="mpmat_stop()" onmouseover="mpmat_start()">
              <img class="pub-thumb" src="images/mpmat/mpmat_fig1.png" alt="MP-Mat" />
              <div class="pub-body">
                <div class="pub-title">MP-Mat: A 3D and Instance-Aware Human Matting and Editing Framework with Multiplane Representation</div>
                <div class="pub-meta">
                  Siyi Jiao*, <u><b>Wenzheng Zeng*<span class="supmark_1">&dagger;</span></b></u>, Yerong Li, Huayu Zhang, Changxin Gao, Nong Sang<span class="supmark_1">&Dagger;</span>, Mike Zheng Shou<span class="supmark_1">&Dagger;</span>
                  <br />
                  <em>ICLR 2025</em>
                </div>
                <div class="pub-links">
                  <a href="https://arxiv.org/pdf/2504.14606">[Paper]</a>
                  <a href="https://github.com/JiaoSiyi/MPMat">[Code]</a>
                </div>
              </div>
            </li>

            <li class="publication-entry" onmouseout="dfimat_stop()" onmouseover="dfimat_start()">
              <img class="pub-thumb" src="images/dfimat/2.png" alt="DFIMat" />
              <div class="pub-body">
                <div class="pub-title">DFIMat: Decoupled Flexible Interactive Matting in Multi-Person Scenarios</div>
                <div class="pub-meta">
                  Siyi Jiao*, <u><b>Wenzheng Zeng*</b></u>, Changxin Gao, Nong Sang
                  <br />
                  <em>ACCV 2024</em>
                </div>
                <div class="pub-links">
                  <a href="https://arxiv.org/pdf/2410.09788">[Paper]</a>
                  <a href="https://github.com/JiaoSiyi/DFIMat">[Code]</a>
                </div>
              </div>
            </li>

            <li class="publication-entry" onmouseout="crossglg_stop()" onmouseover="crossglg_start()">
              <img class="pub-thumb" src="images/cross_glg.png" alt="CrossGLG" />
              <div class="pub-body">
                <div class="pub-title">CrossGLG: LLM Guides One-shot Skeleton-based 3D Action Recognition in a Cross-level Manner</div>
                <div class="pub-meta">
                  Tingbing Yan, <u><b>Wenzheng Zeng<span class="supmark_1">&Dagger;</span></b></u>, Yang Xiao<span class="supmark_1">&Dagger;</span>, Xingyu Tong, Bo Tan, Zhiwen Fang, Zhiguo Cao, Joey Tianyi Zhou
                  <br />
                  <em>ECCV 2024</em>
                </div>
                <div class="pub-links">
                  <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/03008.pdf">[Paper]</a>
                  <a href="https://github.com/Baron-sanmen/CrossGLG">[Code]</a>
                </div>
              </div>
            </li>

            <li class="publication-entry" onmouseout="mcgaze_stop()" onmouseover="mcgaze_start()">
              <img class="pub-thumb" src="images/mcgaze_demo.gif" alt="MCGaze" />
              <div class="pub-body">
                <div class="pub-title">End-to-End Video Gaze Estimation via Capturing Head-Face-Eye Spatial-Temporal Interaction Context</div>
                <div class="pub-meta">
                  Yiran Guan*, Zhuoguang Chen*, <u><b>Wenzheng Zeng<span class="supmark_1">&Dagger;</span></b></u>, Zhiguo Cao, Yang Xiao<span class="supmark_1">&Dagger;</span>
                  <br />
                  <em>IEEE Signal Processing Letters</em>, 2023
                </div>
                <div class="pub-links">
                  <a href="https://arxiv.org/abs/2310.18131">[Paper]</a>
                  <a href="https://github.com/zgchen33/MCGaze">[Code]</a>
                </div>
              </div>
            </li>

            <li class="publication-entry" onmouseout="mpeblink_stop()" onmouseover="mpeblink_start()">
              <img class="pub-thumb" src="images/mpeblink_demo.gif" alt="MPEblink" />
              <div class="pub-body">
                <div class="pub-title">Real-time Multi-person Eyeblink Detection in the Wild for Untrimmed Video</div>
                <div class="pub-meta">
                  <u><b>Wenzheng Zeng</b></u>, Yang Xiao, Sicheng Wei, Jinfang Gan, Xintao Zhang, Zhiguo Cao, Zhiwen Fang, Joey Tianyi Zhou
                  <br />
                  <em>CVPR 2023</em>
                </div>
                <div class="pub-links">
                  <a href="https://wenzhengzeng.github.io/mpeblink">[Project Page]</a>
                  <a href="https://wenzhengzeng.github.io/mpeblink/static/images/mpeblink.pdf">[Paper]</a>
                  <a href="https://www.youtube.com/embed/ngME7dym0Uk">[Video]</a>
                  <a href="mpeblink/static/images/cvpr23_poster.pdf">[Poster]</a>
                  <a href="https://github.com/wenzhengzeng/MPEblink">[Code]</a>
                  <a href="https://zenodo.org/record/7754768">[Dataset]</a>
                </div>
              </div>
            </li>

            <li class="publication-entry" onmouseout="blink_eyelid_stop()" onmouseover="blink_eyelid_start()">
              <img class="pub-thumb" src="images/blink_eyelid_new.png" alt="Blink Eyelid" />
              <div class="pub-body">
                <div class="pub-title">Eyelid’s Intrinsic Motion-aware Feature Learning<br />for Real-time Eyeblink Detection in the Wild</div>
                <div class="pub-meta">
                  <u><b>Wenzheng Zeng</b></u>, Yang Xiao, Guilei Hu, Zhiguo Cao, Sicheng Wei, Zhiwen Fang,<br />
                  Joey Tianyi Zhou, Junsong Yuan
                  <br />
                  <em>IEEE Transactions on Information Forensics and Security (TIFS)</em>, 2023
                </div>
                <div class="pub-links">
                  <a href="data/blink_eyelid_final.pdf">[Paper]</a>
                  <a href="https://github.com/wenzhengzeng/blink_eyelid">[Code]</a>
                </div>
              </div>
            </li>
          </ul>
          
          <h2>Invited Talk</h2>
          <ul class="media-list">
            <li class="media-entry">
              <img class="media-img" src="images/gaze2023_low_res.png" alt="GAZE2023" />
              <div class="media-body">
                <div class="media-title">
                  <strong>Invited poster and spotlight talk at <a href="https://gazeworkshop.github.io/2023/">CVPR GAZE2023 workshop</a>.</strong>
                </div>
                <div class="media-line"><strong>Topic:</strong> Multi-person eyeblink detection in the wild in untrimmed videos.</div>
              </div>
            </li>
          </ul>

          <h2>Competitions</h2>
          <p class="pub-legend">(Team leader or core contributor)</p>
          <ul class="media-list media-list--loose">
            <li class="media-entry">
              <img class="media-img" src="images/logo_new.gif" alt="Challenge Cup" />
              <div class="media-body">
                <div class="media-title"><strong>The "Challenge Cup" National Competition, 2023</strong></div>
                <div class="media-line"><strong>Topic:</strong> Driver Monitoring System (DMS).</div>
                <div class="media-line"><strong>Result:</strong> Winning the <strong>Grand Prize (top prize beyond First Prize), serving as team leader</strong>.</div>
              </div>
            </li>
            <li class="media-entry">
              <img class="media-img" src="images/ECCV-logo3.png" alt="ECCV 2022" />
              <div class="media-body">
                <div class="media-title"><strong>The Visual Inductive Priors for Data-Efficient Computer Vision Challenge, ECCV 2022</strong></div>
                <div class="media-line"><strong>Topic:</strong> Action recognition with limited training data.</div>
                <div class="media-line"><strong>Result:</strong> Obtain <strong>3rd place</strong> and <strong>Jury Prize</strong> in the action recognition track (equal core contribution).</div>
              </div>
            </li>
            <li class="media-entry">
              <img class="media-img" src="images/Parkinson_competition.jpg" alt="AI Innovation Competition 2021" />
              <div class="media-body">
                <div class="media-title"><strong>China Graduate AI Innovation Competition, 2021</strong></div>
                <div class="media-line"><strong>Topic:</strong> Cloud + AI assist Parkinson's Diagnosis.</div>
                <div class="media-line"><strong>Result:</strong> Obtain <strong>3rd place and fisrt prize (3/1505)</strong>.</div>
              </div>
            </li>
            <li class="media-entry">
              <img class="media-img" src="images/ICCV logo_Homepage_sm.png" alt="ICCV 2021" />
              <div class="media-body">
                <div class="media-title"><strong>Fisheye Video-based Action Recognition Competition at the MMVRAC Workshop, ICCV 2021</strong></div>
                <div class="media-line"><strong>Topic:</strong> Action recognition in fisheye videos.</div>
                <div class="media-line"><strong>Result:</strong> Obtain <strong>4th place</strong>.</div>
              </div>
            </li>
            <li class="media-entry">
              <img class="media-img" src="images/COMAP-logo-EF3340.svg" alt="MCM 2020" />
              <div class="media-body">
                <div class="media-title"><strong>The Mathematical Contest In Modeling (MCM), America, 2020</strong></div>
                <div class="media-line"><strong>Topic:</strong> Comprehensive exploration of buyer reviews and ratings for Amazon e-commerce products.</div>
                <div class="media-line"><strong>Result:</strong> Obtain <strong>Meritorious Winner (9%)</strong> (equal core contribution).</div>
              </div>
            </li>
          </ul>
          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tr>
                  <td width="100%" valign="middle">
                    <h2>Selected Awards</h2>
                    <ul>
                      <li>Research Achievement Award, School of Computing, NUS, 2025-2026</li>
                      <li>PhD Research Scholarship, NUS, 2024</li>
                      <li>PhD Fellowship, UCSD, 2024</li>
                      <li>National Scholarship (Rank 1/600+), 2023</li>
                      <li>HUAWEI Scholarship (Rate &lt; 1%), 2023</li>
                      <li>Outstanding Undergraduate, 2021</li>
                      <li>Outstanding Undergraduate Thesis (Rate &lt; 3% in HUST), 2021</li>
                    </ul>
                  </td>
                </tr>
          </table>

          <table style="width:95%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px;width:100%;vertical-align:middle">
                <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=9uNQ2ofFYHm_dpMlwmA0ZP6JyNeR14BDIfGcfmwCp1A"></script>
              </td>
            </tr>
          </tbody></table>

          <!-- <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=9uNQ2ofFYHm_dpMlwmA0ZP6JyNeR14BDIfGcfmwCp1A&cl=ffffff&w=a"></script> -->

          <!-- <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=9uNQ2ofFYHm_dpMlwmA0ZP6JyNeR14BDIfGcfmwCp1A'></script> -->






          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <div id="footer">
                  <div id="footer-text">
                    © Wenzheng Zeng<br />
                    <span class="footer-credit">Template credit: <a href="https://jonbarron.info/" target="_blank" rel="noopener">Jon Barron</a></span>
                  </div>
                </div>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
