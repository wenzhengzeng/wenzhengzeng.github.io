<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Wenzheng Zeng</title>

    <meta name="author" content="Wenzheng Zeng">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  </head>

  <body>
    <!-- <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> -->
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:0.5%;width:72%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  <!-- <span style="font-family: 'Times New Roman', Times, serif;">Wenzheng Zeng</span>  -->
                  Wenzheng Zeng   
                  <span style="font-family: 'SimSun', 'ÂÆã‰Ωì', serif;">ÊõæÊñáÊ≠£</span>
                </p>
              </td>
              <!-- <td style="padding:0.5%;width:30%;vertical-align:middle">
              </td> -->
            </tr>
            <tr style="padding:0px">
              <td style="padding:0.5%;width:72%;vertical-align:middle">   
                <p>I am a first year PhD student at National University of Singapore (NUS), 
                  affiliated with the <a href="https://www.comp.nus.edu.sg/">Department of Computer Science</a> 
                  and <a href="https://sites.google.com/view/showlab/home">Show Lab</a>, 
                  co-supervised by
                  <a href="https://scholar.google.com/citations?user=FABZCeAAAAAJ&hl">Prof. Hwee Tou Ng</a>
                  and
                  <a href="https://scholar.google.com/citations?user=h1-3lSoAAAAJ&hl">Prof. Mike Zheng Shou</a>.
                  I received my B.Eng and M.Phil degree from the
                  <a href="https://aia.hust.edu.cn">School of Artificial Intelligence and Automation</a>,
                  <a href="https://english.hust.edu.cn">Huazhong University of Science and Technology (HUST)</a>, working with 
                  <a href="https://scholar.google.com/citations?user=NeKBuXEAAAAJ&hl">Prof. Yang Xiao</a>
                  and
                  <a href="https://scholar.google.com/citations?user=396o2BAAAAAJ&hl">Prof. Zhiguo Cao</a>, and also collaborating with
                  <a href="https://scholar.google.com/citations?user=cYNqDokAAAAJ&hl">Dr. Joey Tianyi Zhou</a>
                  and
                  <a href="https://scholar.google.com/citations?hl=en&user=fJ7seq0AAAAJ">Prof. Junsong Yuan</a>.

                </p>
                <p>
                  My research interests mainly focus on computer vision, particularly in detection and segmentation in both space and time. Recently, I work on video-language modeling.
                </p>
                <p>
                  My hust.edu.cn email has expired since 2024.9. Feel free to contact me via [wenzhengzeng@u.nus.edu] or [zengwenzheng126@126.com].
                </p>
                <p style="text-align:center">
                  <a href="mailto:wenzhengzeng@u.nus.edu">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com.sg/citations?hl=en&user=RDTJO-4AAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/wenzhengzeng">Github</a> &nbsp;/&nbsp;
                  <a href="https://x.com/alexzeng1206">Twitter</a>

                  
                </p>
              </td>
              <td style="padding:0.5%;width:28%;vertical-align:top">
                <a href="images/zwz3.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/zwz3.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:10px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
                
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
            

            <tr onmouseout="crossglg_stop()" onmouseover="crossglg_start()">
              <td style="padding:10px 20px;width:25%;vertical-align:middle">
                
                <img src="images/cross_glg.png" width="180">
            
                
              </td>
              <td style="padding:10px 20px;width:75%;vertical-align:middle">
                
                <span class="papertitle" style="font-size: 1.06em;">CrossGLG: LLM Guides One-shot Skeleton-based 3D Action Recognition in a Cross-level Manner</span>
                <br>

                Tingbing Yan,
                <u><b>Wenzheng Zeng<sup>#</sup></b></u>,
                Yang Xiao<sup>#</sup></a>,
                Xingyu Tong,
                Bo Tan,
                Zhiwen Fang,
                Zhiguo Cao,
                Joey Tianyi Zhou
                <br>
                (#: corresponding author)
                <br>
                <em>ECCV 2024</em>
                <br>

                <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/03008.pdf">[Paper]</a>
                <a href="https://github.com/Baron-sanmen/CrossGLG">[Code]</a>
                
                
                <p></p>
              </td>
            </tr> 


            <tr onmouseout="mcgaze_stop()" onmouseover="mcgaze_start()">
              <td style="padding:10px 20px;width:25%;vertical-align:middle">
                
                <img src="images/mcgaze_demo.gif" width="180">
            
                
              </td>
              <td style="padding:10px 20px;width:75%;vertical-align:middle">
                
                <span class="papertitle" style="font-size: 1.06em;">End-to-End Video Gaze Estimation via Capturing Head-Face-Eye Spatial-Temporal Interaction Context</span>
                <br>
                <!-- <span><strong>End-to-End Video Gaze Estimation via Capturing Head-Face-Eye Spatial-Temporal Interaction Context</strong></span>
                <br> -->
                Yiran Guan*,
                Zhuoguang Chen*,
                
                <u><b>Wenzheng Zeng<sup>#</sup></b></u>,
                Zhiguo Cao,
                Yang Xiao<sup>#</sup></a>
                <br>
                (*: equal contribution;  #: corresponding author)
                <br>
                <em>IEEE Signal Processing Letters</em>, 2023
                <br>
                
                <a href="https://arxiv.org/abs/2310.18131">[Paper]</a>
                <a href="https://github.com/zgchen33/MCGaze">[Code]</a>
                
                <p></p>
              </td>
            </tr> 
      
    

              
            <tr onmouseout="mpeblink_stop()" onmouseover="mpeblink_start()">
              <td style="padding:10px 20px;width:25%;vertical-align:middle">
                
                <img src="images/mpeblink_demo.gif" width="180">
            
                
              </td>
              <td style="padding:10px 20px;width:75%;vertical-align:middle">
                
                <span class="papertitle" style="font-size: 1.06em;">Real-time Multi-person Eyeblink Detection in the Wild for Untrimmed Video</span>
                <!-- <br> -->
                <!-- <br style="margin-bottom: 1.2em;"> -->
                <div style="margin-bottom: 0.2em;"></div>
                <u><b>Wenzheng Zeng</b></u>,
                Yang Xiao,
                Sicheng Wei,
                Jinfang Gan,
                Xintao Zhang,
                Zhiguo Cao,
                Zhiwen Fang,
                Joey Tianyi Zhou
                <br>
                <em>CVPR 2023</em>
                <br>
                <a href="https://wenzhengzeng.github.io/mpeblink">[Project Page]</a>
                
                <a href="https://wenzhengzeng.github.io/mpeblink/static/images/mpeblink.pdf">[Paper]</a>
                
                <a href="https://www.youtube.com/embed/ngME7dym0Uk">[Video]</a>
                
                <a href="mpeblink/static/images/cvpr23_poster.pdf">[Poster]</a>
              
                <a href="https://github.com/wenzhengzeng/MPEblink">[Code]</a>
                
                <a href="https://zenodo.org/record/7754768">[Dataset]</a>
                
                <p></p>
              </td>
            </tr> 

            <tr onmouseout="blink_eyelid_stop()" onmouseover="blink_eyelid_start()">
              <td style="padding:10px 20px;width:25%;vertical-align:middle">
               
                  <img src='images/blink_eyelid_new.png' width="180">
                
              </td>
              <td style="padding:10px 20px;width:75%;vertical-align:middle">
                
                <span class="papertitle" style="font-size: 1.06em;">Eyelid‚Äôs Intrinsic Motion-aware Feature Learning
                    for Real-time Eyeblink Detection in the Wild</span>
                <div style="margin-bottom: 0.2em;"></div>
                <u><b>Wenzheng Zeng</b></u>,
                Yang Xiao,
                Guilei Hu,
                Zhiguo Cao,
                Sicheng Wei,
                Zhiwen Fang, <br>
                Joey Tianyi Zhou,
                Junsong Yuan
                <br>
                <em>IEEE Transactions on Information Forensics and Security (TIFS)</em>, 2023
                <br>
                
                
                <a href="data/blink_eyelid_final.pdf">[Paper]</a>
                
                <a href="https://github.com/wenzhengzeng/blink_eyelid">[Code]</a>
                <p></p>
              </td>
            </tr>



           

    

          </tbody></table>
          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Invited Talk</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:5px 20px;width:25%;vertical-align:middle">
                <img src="images/gaze2023_low_res.png", width="180"></td>
              <td width="75%" valign="center">
                <span style="font-size: 1.2em;"><strong>Invited poster and spotlight talk at <a href="https://gazeworkshop.github.io/2023/">CVPR GAZE2023 workshop</a>.</strong></span>
                <div style="margin-bottom: 0.2em;"></div> 
                <strong>Topic:</strong> Multi-person eyeblink detection in the wild in untrimmed videos.
                <br>
                
              </td>
            </tr>
        
            
            
          </tbody></table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Competitions</h2>
                <br>
                (Team leader or core contributor) 
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>


            <tr>
              <td style="padding:5px 20px;width:25%;vertical-align:middle">
                <img src="images/logo_new.gif", width="180"></td>
              <td width="75%" valign="center">
                <!-- <span><strong>The "Challenge Cup" National Competition, 2023</strong></span> -->
                <span style="font-size: 1.2em;"><strong>The "Challenge Cup" National Competition, 2023</strong></span>
                <div style="margin-bottom: 0.2em;"></div>
      
                <strong>Topic:</strong> Driver Monitoring System (DMS).
                <br>
                <strong>Result:</strong> Winning the <strong>Grand Prize (top prize beyond First Prize), serving as team leader</strong>.
                <br>
                
              </td>
            </tr>
            
            <tr>
              <td style="padding:5px 20px;width:25%;vertical-align:middle">
                <img src="images/ECCV-logo3.png", width="180"></td>
              <td width="75%" valign="center">
                <!-- <span><strong>The Visual Inductive Priors for Data-Efficient Computer Vision Challenge, ECCV 2022</strong></span> -->
                <span style="font-size: 1.2em;"><strong>The Visual Inductive Priors for Data-Efficient Computer Vision Challenge, ECCV 2022</strong></span>
                <div style="margin-bottom: 0.2em;"></div>
                
                <strong>Topic:</strong> Action recognition with limited training data.
                <br>
                <strong>Result:</strong> Obtain <strong>3rd place</strong> and <strong>Jury Prize</strong> in the action recognition track (equal core contribution).
                <br>
                
              </td>
            </tr>


            <tr>
              <td style="padding:5px 20px;width:25%;vertical-align:middle">
                <img src="images/Parkinson_competition.jpg", width="180"></td>
              <td width="75%" valign="center">
                <!-- <span><strong>China Graduate AI Innovation Competition, 2021</strong></span> -->
                <span style="font-size: 1.2em;"><strong>China Graduate AI Innovation Competition, 2021</strong></span>
                <div style="margin-bottom: 0.2em;"></div>
                
                <strong>Topic:</strong> Cloud + AI assist Parkinson's Diagnosis.
                <br>
                <strong>Result:</strong> Obtain <strong>3rd place and fisrt prize (3/1505)</strong>.
                <br>
                
              </td>
            </tr>

            <tr>
              <td style="padding:5px 20px;width:25%;vertical-align:middle">
                <img src="images/ICCV logo_Homepage_sm.png", width="180"></td>
              <td width="75%" valign="center">
                <!-- <span><strong>Fisheye Video-based Action Recognition Competition at the MMVRAC Workshop, ICCV 2021</strong></span> -->
                <span style="font-size: 1.2em;"><strong>Fisheye Video-based Action Recognition Competition at the MMVRAC Workshop, ICCV 2021</strong></span>
                <div style="margin-bottom: 0.2em;"></div>
                
                <strong>Topic:</strong> Action recognition in fisheye videos.
                <br>
                <strong>Result:</strong> Obtain <strong>4th place</strong>.
                <br>
                
              </td>
            </tr>

            <tr>
              <td style="padding:5px 20px;width:25%;vertical-align:middle">
                <img src="images/COMAP-logo-EF3340.svg", width="170"></td>
              <td width="75%" valign="center">
                <!-- <span><strong>The Mathematical Contest In Modeling (MCM), America, 2020</strong></span> -->
                <span style="font-size: 1.15em;"><strong>The Mathematical Contest In Modeling (MCM), America, 2020</strong></span>
                <div style="margin-bottom: 0.2em;"></div>
                
                <strong>Topic:</strong> Comprehensive exploration of buyer reviews and ratings for Amazon e-commerce products.
                <br>
                <strong>Result:</strong> Obtain <strong>Meritorious Winner (9%)</strong> (equal core contribution).
                <br>
                
              </td>
            </tr>


            
          </tbody></table>


          <p></p><p></p><p></p><p></p><p></p>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tr>
                  <td width="100%" valign="middle">
                    <h2>Selected Awards</h2>
                    <div style="line-height:25px">
                    <p>
                <li> <stronghuge>PhD Research Scholarship, NUS,&nbsp; 2024<br/>
                <li> <stronghuge>PhD Fellowship, UCSD,&nbsp; 2024<br/>
                <li> <stronghuge>National Scholarship (Rank 1/600+),&nbsp; 2023<br/>
                <li> <stronghuge>HUAWEI Scholarship (Rate < 1%), &nbsp; 2023<br/>
                <li> <stronghuge>Outstanding Undergraduate,&nbsp; 2021<br/>
                <li> <stronghuge>Outstanding Undergraduate Thesis </stronghuge> (Rate < 3% in HUST),&nbsp; 2021<br/>
  
                    </p>
                    </div>
                  </td>
                </tr>
          </table>

          <table style="width:95%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px;width:100%;vertical-align:middle">
                <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=9uNQ2ofFYHm_dpMlwmA0ZP6JyNeR14BDIfGcfmwCp1A"></script>
              </td>
            </tr>
          </tbody></table>

          <!-- <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=9uNQ2ofFYHm_dpMlwmA0ZP6JyNeR14BDIfGcfmwCp1A&cl=ffffff&w=a"></script> -->

          <!-- <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=9uNQ2ofFYHm_dpMlwmA0ZP6JyNeR14BDIfGcfmwCp1A'></script> -->






          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  This website is inspired by <a href="https://jonbarron.info/">Jon Barron's website</a>. Many thanks to him!
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
