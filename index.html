<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Wenzheng Zeng</title>

    <meta name="author" content="Wenzheng Zeng">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Wenzheng Zeng ÊõæÊñáÊ≠£
                </p>
                <p>I am a master‚Äôs student at the School of Artificial Intelligence and Automation, Huazhong University of Science and Technology (HUST), advised by <a href="https://scholar.google.com/citations?user=NeKBuXEAAAAJ&hl=en">Prof. Yang Xiao</a>. Before that, I received my bachelor's degree from HUST in 2021.
                </p>
                <p>
                  My research interests include machine learning and computer version. Currently, my main research efforts are on eyeblink detection and gaze estimation. I have also participated in several top competitions, primarily focused on video understanding and math modeling. 
                </p>
                <p style="text-align:center">
                  <a href="wenzhengzeng@hust.edu.cn">Email</a> &nbsp;/&nbsp;
                  <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp; -->
                  <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com.sg/citations?hl=en&user=RDTJO-4AAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                  <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp;/&nbsp; -->
                  <a href="https://github.com/wenzhengzeng">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/zwz.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/zwz.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
    


      
    


              
            <tr onmouseout="mpeblink_stop()" onmouseover="mpeblink_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                
                <img src="images/mpeblink_demo.gif" width="180">
            
                
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://wenzhengzeng.github.io/mpeblink">
                  <span class="papertitle">Real-time Multi-person Eyeblink Detection in the Wild for Untrimmed Video</span>
                </a>
                <br>
                <strong>Wenzheng Zeng</strong>,
                <a href="https://scholar.google.com/citations?user=NeKBuXEAAAAJ&hl=en">Yang Xiao</a>,
                Sicheng Wei,
                Jinfang Gan,
                Xintao Zhang,
                <a href="https://scholar.google.com/citations?hl=en&user=396o2BAAAAAJ">Zhiguo Cao</a>,
                <a href="https://scholar.google.com/citations?user=UX5N_FQAAAAJ&hl=en">Zhiwen Fang</a>,
                <a href="https://joeyzhouty.github.io/">Joey Tianyi Zhou</a>
                <br>
                <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023
                <br>
                <a href="https://wenzhengzeng.github.io/mpeblink">project page</a>
                /
                <a href="https://wenzhengzeng.github.io/mpeblink/static/images/mpeblink.pdf">paper</a>
                /
                <a href="https://www.youtube.com/embed/ngME7dym0Uk">video</a>
                /
                <a href="https://github.com/wenzhengzeng/MPEblink">code</a>
                <p></p>
              </td>
            </tr> 

            <tr onmouseout="blink_eyelid_stop()" onmouseover="blink_eyelid_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
               
                  <img src='images/blink_eyelid.png' width="180">
                
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://dorverbin.github.io/eclipse">
                  <span class="papertitle">Eyelid‚Äôs Intrinsic Motion-aware Feature Learning
                    for Real-time Eyeblink Detection in the Wild</span>
                </a>
                <br>
                <strong>Wenzheng Zeng</strong>,
                <a href="https://scholar.google.com/citations?user=NeKBuXEAAAAJ&hl=en">Yang Xiao</a>,
                Guilei Hu,
                <a href="https://scholar.google.com/citations?hl=en&user=396o2BAAAAAJ">Zhiguo Cao</a>,
                Sicheng Wei,
                <a href="https://scholar.google.com/citations?user=UX5N_FQAAAAJ&hl=en">Zhiwen Fang</a>, <br>
                <a href="https://joeyzhouty.github.io/">Joey Tianyi Zhou</a>,
                <a href="https://cse.buffalo.edu/~jsyuan/">Junsong Yuan</a>
                <br>
                <em>IEEE Transactions on Information Forensics and Security (TIFS)</em>, 2023
                <br>
                
                /
                <a href="https://www.youtube.com/watch?v=amQLGyza3EU">video</a>
                /
                <a href="data/blink_eyelid_final.pdf">paper</a>
                /
                <a href="https://github.com/wenzhengzeng/blink_eyelid">code</a>
                <p></p>
              </td>
            </tr>



           

    

          </tbody></table>
          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Invited Talk</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/gaze2023_low_res.png", width="180"></td>
              <td width="75%" valign="center">
                <span><strong>Invited poster and Spotlight talk at <a href="https://gazeworkshop.github.io/2023/">CVPR GAZE2023 workshop</a>.</strong></span>
          <br>
                Topic: Multi-person eyeblink detection in the wild in untrimmed videos
                <br>
                
              </td>
            </tr>
        
            
            
          </tbody></table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Competitions</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/ECCV-logo3.png", width="180"></td>
              <td width="75%" valign="center">
                <span><strong>The Visual Inductive Priors for Data-Efficient Computer Vision Challenge, ECCV 2022</strong></span>
          <br>
                Obtain <strong>3rd place</strong> and <strong>Jury Prize</strong> in the action recognition track.
                <br>
                
              </td>
            </tr>


            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/Parkinson_competition.jpg", width="180"></td>
              <td width="75%" valign="center">
                <span><strong>China Graduate AI Innovation Competition, 2021</strong></span>
          <br>
                Obtain <strong>3rd place and fisrt prize (3/1505)</strong>.
                <br>
                
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/ICCV logo_Homepage_sm.png", width="180"></td>
              <td width="75%" valign="center">
                <span><strong>Fisheye Video-based Action Recognition Competition at the MMVRAC Workshop, ICCV 2021</strong></span>
          <br>
                Obtain <strong>4th place</strong>.
                <br>
                
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/COMAP-logo-EF3340.svg", width="170"></td>
              <td width="75%" valign="center">
                <span><strong>The Interdisciplinary Contest In Modeling (ICM), America, 2020.</strong></span>
          <br>
                Obtain <strong>Meritorious Winner (9%)</strong>.
                <br>
                
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/logo_new.gif", width="180"></td>
              <td width="75%" valign="center">
                <span><strong>The "Challenge Cup" National Competition, 2023.</strong></span>
          <br>
                The competition is ongoing and currently in the semifinals, with the top 50 out of 466 teams.
                <br>
                
              </td>
            </tr>
        
            
            
          </tbody></table>






          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  This website is inspired by <a href="https://jonbarron.info/">Jon Barron's website</a>. Many thanks to him!
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
